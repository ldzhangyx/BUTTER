{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.distributions import Normal\n",
    "import random\n",
    "import numpy as np\n",
    "import pysnooper\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# s = torch.ones([32,40])\n",
    "# d = torch.ones([32,40])\n",
    "# torch.stack([s,d],1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = nn.Embedding(10, 3)\n",
    "# input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "# embedding(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisentangledVAE(nn.Module):\n",
    "    def __init__(self,\n",
    "             roll_dims,\n",
    "             hidden_dims,\n",
    "             embed_dims,\n",
    "             feature_dims,\n",
    "             z_other_dims,\n",
    "             word2idx,\n",
    "             n_step,\n",
    "             k=1000):\n",
    "        super().__init__()\n",
    "        self.gru_0 = nn.GRU(\n",
    "            roll_dims,\n",
    "            hidden_dims,\n",
    "            batch_first=True,\n",
    "            bidirectional=True)\n",
    "        self.feature_dims = feature_dims\n",
    "        z_key_dims,z_meter_dims,z_culture_dims = feature_dims, feature_dims, feature_dims # 兼容性写法\n",
    "        self.z_dims = z_key_dims + z_meter_dims + z_culture_dims + z_other_dims\n",
    "        self.z_key_dims = z_key_dims\n",
    "        self.z_meter_dims = z_meter_dims\n",
    "        self.z_culture_dims = z_culture_dims\n",
    "        self.z_other_dims = z_other_dims\n",
    "        \n",
    "        self.linear_mu = nn.Linear(hidden_dims * 2, self.z_dims)\n",
    "        self.linear_var = nn.Linear(hidden_dims * 2, self.z_dims)\n",
    "        self.grucell_1 = nn.GRUCell(self.z_dims + roll_dims,\n",
    "                                        hidden_dims)\n",
    "        self.grucell_2 = nn.GRUCell(hidden_dims, hidden_dims)\n",
    "        self.linear_init = nn.Linear(self.z_dims, hidden_dims)\n",
    "        self.linear_out = nn.Linear(hidden_dims, roll_dims)\n",
    "        self.n_step = n_step\n",
    "        self.sample = None\n",
    "        self.roll_dims = roll_dims\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.eps = 1\n",
    "        self.iteration = 0\n",
    "        self.sample = None\n",
    "        self.k = torch.FloatTensor([k])\n",
    "        \n",
    "        # NLP: word to embeddings\n",
    "        self.embed_dims = embed_dims\n",
    "        self.word2idx = word2idx\n",
    "#         self.linear_dims = 8\n",
    "        self.word_embeds = nn.Embedding(len(self.word2idx), self.embed_dims)\n",
    "        \n",
    "        self.music_embeds = nn.Linear(self.feature_dims, self.embed_dims)\n",
    "        \n",
    "        self.weight_init()\n",
    "    \n",
    "    def weight_init(self):\n",
    "        for p in self.parameters():\n",
    "            if type(p) == nn.GRU:\n",
    "                torch.nn.init.orthogonal_(p)\n",
    "            elif type(p) == nn.Linear:\n",
    "                torch.nn.init.normal_()\n",
    "#             else:\n",
    "#                 torch.nn.init.normal_(p, 0, 1)\n",
    "    \n",
    "    def _sampling(self, x):\n",
    "        idx = x.max(1)[1]\n",
    "        x = torch.zeros_like(x)\n",
    "        arange = torch.arange(x.size(0)).long()\n",
    "        if torch.cuda.is_available():\n",
    "            arange = arange.cuda()\n",
    "        x[arange, idx] = 1\n",
    "        return x\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        _, x = self.gru_0(x)\n",
    "        x = x.transpose_(0, 1).contiguous()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.linear_mu(x)\n",
    "        var = self.linear_var(x).exp_()\n",
    "        distribution = Normal(mu, var) \n",
    "        return distribution, mu, var\n",
    "\n",
    "    def decoder(self, z):\n",
    "        out = torch.zeros((z.size(0), self.roll_dims))\n",
    "        out[:, -1] = 1.\n",
    "        x = []\n",
    "        t = torch.tanh(self.linear_init(z))\n",
    "        hx = t\n",
    "        if torch.cuda.is_available():\n",
    "            out = out.cuda()\n",
    "        for i in range(self.n_step):\n",
    "            out = torch.cat([out, z], 1)\n",
    "            hx = self.grucell_1(out, hx)\n",
    "            out = F.log_softmax(self.linear_out(hx), 1)\n",
    "            x.append(out)\n",
    "            if self.training:\n",
    "                p = torch.rand(1).item()\n",
    "                if p < self.eps:\n",
    "                    out = self.sample[:, i, :]\n",
    "                else:\n",
    "                    out = self._sampling(out)\n",
    "                self.eps = self.k / \\\n",
    "                    (self.k + torch.exp(self.iteration / self.k))\n",
    "            else:\n",
    "                out = self._sampling(out)\n",
    "        return torch.stack(x, 1)\n",
    "    \n",
    "    def language_encoder(self, keywords):\n",
    "        language_index = torch.transpose(torch.LongTensor([[self.word2idx[str(j)]  for j in i] for i in keywords]).cuda(), 0, 1)\n",
    "        language_matrix = self.word_embeds(language_index)\n",
    "        return language_matrix, language_index\n",
    "    \n",
    "    def music_encoder(self, z):\n",
    "#         z = dis.mean\n",
    "        z_key = z[:,:self.feature_dims].clone()\n",
    "        z_meter = z[:,self.feature_dims: 2* self.feature_dims].clone()\n",
    "        z_culture = z[:,2*self.feature_dims: 3*self.feature_dims].clone()\n",
    "        z_matrix = torch.stack([self.music_embeds(z_key), self.music_embeds(z_meter), self.music_embeds(z_culture)], 1)\n",
    "        \n",
    "        return z_matrix\n",
    "        \n",
    "    def forward(self, x, keywords):\n",
    "        if self.training:\n",
    "            self.sample = x\n",
    "            self.iteration += 1\n",
    "        dis, mu, var = self.encoder(x)\n",
    "        if self.training:\n",
    "            z = dis.rsample()\n",
    "        else:\n",
    "#             z = dis.mean\n",
    "            z = dis.rsample()\n",
    "        z_matrix = self.music_encoder(dis.mean)\n",
    "        recon = self.decoder(z)\n",
    "        language_matrix, language_index = self.language_encoder(keywords) # key, meter, culture\n",
    "        output = (recon, dis.mean, dis.stddev, language_index, z_matrix, )\n",
    "#         pdb.set_trace()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
